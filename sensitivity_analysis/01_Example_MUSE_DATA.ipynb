{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we would like to perform PSF esitmation and deconvolution on some real data. We took the ganymede as an example. \n",
    "\n",
    "A few things need to consider: \n",
    "- Can we perform any estimation on the strehl ratio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "\n",
    "# Packages required\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from astropy.io import fits\n",
    "import os\n",
    "from deconvbench import Deconvbench\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from amiral import instructment, utils, parameter, gradient, minimisation, array, plotting\n",
    "from astropy.visualization import make_lupton_rgb\n",
    "import scipy\n",
    "\n",
    "\n",
    "# from plotting import plot_PSF_PSD as amiral_plt\n",
    "from scipy.optimize import minimize \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import tools\n",
    "\n",
    "rcParams[\"figure.figsize\"] = 20,33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting snr\n",
    "def snr_map (array, n_sky, n_ron): \n",
    "    \n",
    "    # S/N = S/N_tot = S /  sqrt (S+Sky+Dark +N_ron^2)\n",
    "    # As the RON is small, we can ignore that \n",
    "    # Sky: background -> get the mean value of the background from the corner\n",
    "    \n",
    "    dimension = np.shape(array)[0]\n",
    "    snr_map =  np.zeros((dimension,dimension))\n",
    "    snr_map[:,:] = array[:,:] / np.sqrt(array[:,:] + n_sky + n_ron**2)\n",
    "    \n",
    "    return snr_map\n",
    "\n",
    "def get_snr (array):\n",
    "    \n",
    "    mean = np.mean(array)\n",
    "    sig2 = np.std(array)\n",
    "    \n",
    "    snr = mean / sig2\n",
    "    \n",
    "    return snr\n",
    "\n",
    "def psd_object (param):\n",
    "    \n",
    "    rho = np.fft.fftshift(utils.dist(768))/param[1]\n",
    "    psd_obj =  param[0]/ (np.power(rho,param[2]) + 1.)\n",
    "    \n",
    "    return psd_obj\n",
    "    \n",
    "def plot_psd_object(psd_obj): \n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ycent = int((256*aosys_cls.samp_factor[0])//2)\n",
    "\n",
    "    ax.plot(np.abs(psd_obj[ycent,...]))\n",
    "    ax.set_title('PSD Object(total)')\n",
    "    ax.axhline(y=1, color = 'r', ls = '--')\n",
    "    \n",
    "    pass\n",
    "\n",
    "def create_psfao19_otf (otf_tel, guess, aosys_cls): \n",
    "    \n",
    "    # Use PSFAO19 model to create a PSF\n",
    "    psd_ao = aosys_cls.psd_residual_ao (guess = guess)\n",
    "    psd_halo = aosys_cls.psd_residual_halo(r0 = guess[0])\n",
    "    \n",
    "    psd = psd_ao + psd_halo\n",
    "\n",
    "    otf_atmo = aosys_cls.otf_atmo(psd)\n",
    "    otf_total = otf_atmo*otf_tel\n",
    "      \n",
    "    return otf_atmo,otf_total\n",
    "\n",
    "\n",
    "def resize_array (array, size):\n",
    "    \"\"\"\n",
    "    Resize the array to a given size. \n",
    "    \"\"\"\n",
    "    \n",
    "    cent = np.shape(array)\n",
    "    zoomed_array = array[cent[0]//2 - size//2:cent[0]//2 +size//2, cent[0]//2 - size//2:cent[0]//2 +size//2]\n",
    "    \n",
    "    return zoomed_array\n",
    "\n",
    "\n",
    "def zero_padding(array, pad):\n",
    "    \n",
    "    (_nx, _ny) = array.shape\n",
    "    \n",
    "    nx = _nx * pad \n",
    "    ny = _ny * pad \n",
    "    \n",
    "    print(nx,ny)\n",
    "    \n",
    "    array_resize = np.zeros((nx, ny))\n",
    "    \n",
    "    dx = _nx*pad//2 - _nx//2\n",
    "    dy = _ny*pad//2 - _ny//2\n",
    "    \n",
    "    print(array_resize.shape)\n",
    "    \n",
    "    array_resize[dx:dx+_nx,dy:dy+_ny] = array\n",
    "    \n",
    "    return array_resize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH\n",
    "\n",
    "wdir = \"/Users/alau/Data/MUSE_DATA/Ganymede/2019sep08/\"\n",
    "data_cube = [\"Ganymede_clean_cube_1\", \"Ganymede_clean_cube_2\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the actual data before performing any data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _data = fits.open(wdir+data_fname+\".fits\")\n",
    "# _data.info()\n",
    "\n",
    "# data = _data[0].data\n",
    "\n",
    "_cube = fits.open(wdir+data_cube[1]+\".fits\")\n",
    "_cube.info()\n",
    "\n",
    "cube = _cube[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the SNR\n",
    "\n",
    "# snr_slice = get_snr(data)\n",
    "# snr_cube = get_snr(array)\n",
    "\n",
    "# print(snr_slice,snr_cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information from the input image\n",
    "DIMENSION = np.shape(cube[0])[0]\n",
    "FLUX = np.sum(cube[0]) # Check the unit and make sure you know what it is\n",
    "\n",
    "wvl = _cube[1].header['CRVAL3']*1e-10/1e-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a slice out for analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 100\n",
    "_slice = cube[num]\n",
    "wvl = _cube[1].header['CRVAL3']*1e-10/1e-9 + num*_cube[1].header['CD3_3']*1e-10/1e-9\n",
    "print(wvl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other vairables from the VLT-MUSE instrument\n",
    "RON = 15. # CCD read-out noise standard-deviation [e-]\n",
    "GAIN = 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the object from the high resolution simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aosys_dict = {\n",
    "    'diameter': 8. , \n",
    "    'occ_ratio': 0.14 , \n",
    "    'no_acutuator' : 39, \n",
    "    'wavelength': wvl, \n",
    "    'dimension': DIMENSION,\n",
    "    'resolution_rad' : 1.1977272727272726e-07\n",
    "}\n",
    "\n",
    "print(wvl)\n",
    "\n",
    "# Passing parametpsd_arrayers from the telesope to the aosystem\n",
    "aosys_cls = instructment.aoSystem( \n",
    "        diameter = aosys_dict['diameter'], occ_ratio = aosys_dict['occ_ratio'], \n",
    "        no_acutuator= aosys_dict['no_acutuator'], wavelength = aosys_dict['wavelength']*1e-9, \n",
    "        resolution_rad = aosys_dict['resolution_rad'], \n",
    "        dimension=aosys_dict['dimension'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a PSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the telescope and produce a PSF\n",
    "amiral_dict = {\n",
    "    \"r0\": 0.25,                  \n",
    "    \"background\": 1e-7,      \n",
    "    \"amplitude\": 2.5,       \n",
    "    \"ax\": 0.05,                            \n",
    "    \"beta\": 1.5, \n",
    "    \"mu\": 0., \n",
    "    \"rho0\": 0., \n",
    "    \"p\": 3.0\n",
    "}\n",
    "\n",
    "amiral_keys, psf_guess = utils.dict2array(amiral_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft_zoom_array = zoom_array(np.fft.fftshift(ft_array), 50)\n",
    "# ft_zoom_padded = zoom_array(np.fft.fftshift(ft_data_resize), 50)\n",
    "\n",
    "# fig, ax = plt.subplots(1,2)\n",
    "\n",
    "# rcParams['figure.figsize'] = 16,21\n",
    "\n",
    "# divider = make_axes_locatable(ax[0])\n",
    "# cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "# im = ax[0].imshow(np.real(np.log10(np.fft.fftshift(ft_array))),cmap = 'gray')\n",
    "# fig.colorbar(im,cax ,ax=ax[0])\n",
    "# ax[0].set_title('Array',fontsize = 18)\n",
    "\n",
    "# divider = make_axes_locatable(ax[1])\n",
    "# cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "# im1 = ax[1].imshow(np.real(np.log10(np.fft.fftshift(ft_data_resize))),cmap = 'gray')\n",
    "# fig.colorbar(im1, cax ,ax=ax[1])\n",
    "# ax[1].set_title('Padded array', fontsize = 18)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_masked = np.ma.masked_invalid(cube)\n",
    "_ind = np.where(cube_masked[0].mask == True)\n",
    "\n",
    "cube_masked[0][_ind] = 0\n",
    "# img = cube_masked[0]\n",
    "# img = data_resize\n",
    "\n",
    "img = _slice\n",
    "amiralparam = parameter.amiralParam(img ,guess = psf_guess, aosys = aosys_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What variables to be minimised\n",
    "param_mask = np.asarray([1,1,1,1,1])\n",
    "hyper_param_mask = np.asarray([1,1,0])\n",
    "\n",
    "mask = np.concatenate((param_mask,hyper_param_mask))\n",
    "\n",
    "hyper_guess = amiralparam.hyperparam_initial(psf_guess)\n",
    "hyper_min, hyper_max = amiralparam.hyperparam_bound(psf_guess, p_upperbound = 100.)\n",
    "\n",
    "psf_guess[-3] = hyper_guess[0] \n",
    "psf_guess[-2] = hyper_guess[1] \n",
    "psf_guess[-1] = hyper_guess[2] \n",
    "\n",
    "# r, background, sig2, ax, beta\n",
    "param_min = np.asarray([0.1,0,0,1e-8,1.01])\n",
    "param_max =  np.asarray([0.99,1e8,1e8,3,10])\n",
    "\n",
    "upperbound = np.concatenate((param_max, hyper_max))\n",
    "lowerbound = np.concatenate((param_min, hyper_min))\n",
    "\n",
    "param_numerical_condition = np.array([1., 1e-4, 1., 1., 1.])\n",
    "hyperparam_numerical_condition = np.array([hyper_guess[0], hyper_guess[1], 1.])\n",
    "\n",
    "numerical_condition = np.concatenate((param_numerical_condition, hyperparam_numerical_condition))\n",
    "\n",
    "amiral_cls = parameter.amiral(img=img, guess=psf_guess, aosys = aosys_cls, upperbound = upperbound, lowerbound= lowerbound, numerical_condition = numerical_condition, fourier_variable = amiralparam.fourier_variable, mask = mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "est_criterion, value_criterion, value_grad = amiral_cls.minimisation(psf_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(est_criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_ao = aosys_cls.psd_residual_ao (est_criterion)\n",
    "psd_halo = aosys_cls.psd_residual_halo(est_criterion[0])\n",
    "\n",
    "psd = psd_halo + psd_ao \n",
    "\n",
    "pupil = aosys_cls.get_pupil_plane()\n",
    "otf_tel = aosys_cls.pupil_to_otf_tel(pupil)\n",
    "\n",
    "est_otf_atmo, est_otf = create_psfao19_otf(otf_tel, est_criterion[0:5], aosys_cls)\n",
    "est_psf = np.fft.ifft2(np.fft.ifftshift(est_otf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_tel = np.fft.ifft2(otf_tel)\n",
    "est_SR = np.max(np.real(est_psf)) / np.max(np.real(psf_tel))\n",
    "# SR = np.max(psf_total) / np.max(psf_tel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_SR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intake the estimated criterion for plotting the PSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SNR map\n",
    "# n_ron = np.sqrt(98*15**2)\n",
    "\n",
    "# _map = snr_map(data_resize,16000., n_ron)\n",
    "\n",
    "# plt.imshow(_map)\n",
    "\n",
    "# print(np.min(_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebin(im, bin):\n",
    "    \"\"\"\n",
    "    Rebin an image im by bins of size bin x bin. Taken from\n",
    "    https://www.southampton.ac.uk/~sdc1g08/AstropyFitsImageRebin.py\n",
    "    :param im: Input image, 2D array\n",
    "    :param bin: bin size in pixels, integer\n",
    "    :return: Binned image\n",
    "\n",
    "    \"\"\"\n",
    "    # Resize array by getting rid of extra columns and rows\n",
    "    xedge = np.shape(im)[0] % bin\n",
    "    yedge = np.shape(im)[1] % bin\n",
    "    im = im[xedge:, yedge:]\n",
    "\n",
    "    # Reshape image to new size\n",
    "    binim = np.reshape(im, (int(np.shape(im)[0] / bin), bin, int(np.shape(im)[1] / bin), bin))\n",
    "\n",
    "    # Sum each bin x bin subarray\n",
    "    binim = np.sum(binim, axis=3)\n",
    "    binim = np.sum(binim, axis=1)\n",
    "\n",
    "    return binim\n",
    "\n",
    "binned_psf = rebin(est_psf, aosys_cls.samp_factor[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Output the file to a fits file in here\n",
    "# hdu1 = fits.PrimaryHDU()\n",
    "# hdu2 = fits.ImageHDU(data=np.real(binned_psf))\n",
    "# new_hdul = fits.HDUList([hdu1, hdu2])\n",
    "\n",
    "# hdr = new_hdul[1].header\n",
    "\n",
    "# new_hdul.info()\n",
    "\n",
    "# import datetime\n",
    "\n",
    "# # Get the today's date\n",
    "# date  = datetime.datetime.now()\n",
    "\n",
    "# # Add the date to the header\n",
    "\n",
    "# hdr['r0'] = est_criterion[0]\n",
    "# hdr['bck']= est_criterion[1]\n",
    "# hdr['sig2'] = est_criterion[2]\n",
    "# hdr['ax']  = est_criterion[3]\n",
    "# hdr['beta']  = est_criterion[4]\n",
    "# hdr['mu']  = est_criterion[5]\n",
    "# hdr['rho0']  = est_criterion[6]\n",
    "# hdr['p']  = est_criterion[7]\n",
    "# hdr['DATE'] = date.strftime(\"%Y-%m-%d\")\n",
    "# hdr['wvl(A)'] = 7307\n",
    "\n",
    "# # the name can input from the .ini file\n",
    "# array.save_fits(img_obj=new_hdul, name = os.path.join('psf_wvl_7307'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_param = est_criterion[0:5]\n",
    "est_otf_atmo, est_otf_total = create_psfao19_otf(otf_tel,est_param,aosys_cls)\n",
    "\n",
    "\n",
    "from amiral.plotting import plotting_PSF_PSD\n",
    "# Plot the PSF slice\n",
    "rcParams['figure.figsize'] = 11,9\n",
    "\n",
    "ycent = int((est_psf.shape[0]//2))\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_title(r\"PSF Estimation (with noise)$\\mathrm{ \\{p_{fixed} \\}}$\"\n",
    "             \"\\nSR Error: %.2f %%\\nFlux[e-]: %.2E\\nWvl: %.2fnm\" %(0,0,wvl),fontsize = 18)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel(r'$\\mathrm{Mean Intensity [e^-]}$', fontsize = 18)\n",
    "ax.set_xlabel(r'$\\mathrm{Position [pixel]}$', fontsize = 18)\n",
    "# ax.plot(utils.mean_cir_array(np.real(psf_total)), label = \"True\")\n",
    "ax.plot(utils.mean_cir_array(np.real(binned_psf)), label = \"Estimated PSF\")\n",
    "ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "ax.legend()\n",
    "\n",
    "# fig.savefig('/Users/alau/Data/amiral_fits/VESTA/SNR/2021apr06/deconv/VESTA_PSF_Estimation.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(r\"Estimated PSF cut$\\mathrm{ \\{p_{fixed} \\}}$\"\n",
    "             \"\\nSR Error: %.2f %%\\nFlux[e-]: %.2E\\nWvl: %.2fnm\" %(0,0,wvl),fontsize = 18)\n",
    "\n",
    "ycent = int((binned_psf.shape[0]//2))\n",
    "\n",
    "plt.plot(binned_psf[ycent,:])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # masking\n",
    "\n",
    "# def masking (array, pad): \n",
    "    \n",
    "#     (_nx, _ny) = array.shape\n",
    "    \n",
    "#     nx = _nx * pad \n",
    "#     ny = _ny * pad \n",
    "    \n",
    "#     print(nx,ny)\n",
    "    \n",
    "#     mask = np.full((nx,ny),False, dtype=bool)\n",
    "#     _mask_arr = np.full((_nx,_ny),True, dtype=bool)\n",
    "    \n",
    "#     dx = _nx*pad//2 - _nx//2\n",
    "#     dy = _ny*pad//2 - _ny//2\n",
    "    \n",
    "#     mask[dx:dx+_nx,dy:dy+_ny] = _mask_arr\n",
    "    \n",
    "#     return mask\n",
    "\n",
    "# mask = masking(data, aosys_cls.samp_factor[0])\n",
    "\n",
    "# plt.imshow(mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maoppy.instrument import muse_nfm\n",
    "\n",
    "deadMap = np.full((cube_masked[0].shape),True, dtype=bool)\n",
    "\n",
    "bad = np.where(img == 0) # all columns and rows in [i]\n",
    "deadMap[bad[0],bad[1]] = False\n",
    "\n",
    "plt.imshow(deadMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binned\n",
    "import time\n",
    "start_time = time.time()\n",
    "dec = Deconvbench(img, binned_psf,ron = 15)\n",
    "# dec.weights *= ~deadMap # take into account dead pixels\n",
    "dec.verbose_modulo = 500 # print every 10 iteration\n",
    "dec.regularization.scale *= 4. # sharpen details (reduce regularization)\n",
    "# weights in here can be a mask as the snr is calculated interna;;y\n",
    "\n",
    "estim = dec.run()\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "\n",
    "print(\"Run Time (mintues): \",runtime/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right, we have the deconvolved object now. Is the flux conserved? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Flux of the image [e-]: %f\" %(np.sum(data)))\n",
    "# print(\"Flux of the deconvolved object: %f\" %(np.sum(estim)))\n",
    "# print(\"Flux difference [%%]: %f\" %(np.sum(data-estim)/np.sum(data_resize)))\n",
    "\n",
    "def write2header (param,wvl,flux,snr,keys): \n",
    "\n",
    "    hdr = fits.Header()\n",
    "\n",
    "    param = np.append(param, flux)\n",
    "    param = np.append(param, snr)\n",
    "    param = np.append(param, wvl)\n",
    "\n",
    "    for i in range (len(keys)): \n",
    "        hdr[keys[i]] = param[i]\n",
    "\n",
    "    return hdr\n",
    "\n",
    "hdr = write2header (est_criterion,0.,0.,wvl,amiral_keys) \n",
    "\n",
    "data_dir = \"/Users/alau/Data/amiral_fits/ganymede_cube/deconv/\"\n",
    "\n",
    "# fits.writeto(data_dir+\"ganymede_\"+str(wvl)+\"_binned_10\"+'.fits', estim, hdr)\n",
    "\n",
    "os.getcwd()\n",
    "\n",
    "plt.imshow(estim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# zoom into the array\n",
    "\n",
    "# zoom_residual = zoom_array(estim-asteriod_resize, 200)\n",
    "\n",
    "fig, ax = plt.subplots(1,3)\n",
    "rcParams['figure.figsize'] = 19,21\n",
    "fig.tight_layout(pad=1.0, w_pad=1.0, h_pad=5.0)\n",
    "\n",
    "divider = make_axes_locatable(ax[0])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "im = ax[0].imshow(resize_array(estim,128),cmap = 'gray')\n",
    "# im = ax[0].imshow(estim,cmap = 'gray')\n",
    "fig.colorbar(im,cax ,ax=ax[0])\n",
    "ax[0].set_title('L2-L1 Deconvolved with the esitmated PSF''\\nFlux [e-]: %.2E''\\nWvl: %.3fnm'%(np.sum(resize_array(estim,128)),wvl), fontsize = 14)\n",
    "\n",
    "divider = make_axes_locatable(ax[1])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "im1 = ax[1].imshow(resize_array(img,128),cmap = 'gray')\n",
    "fig.colorbar(im1, cax ,ax=ax[1])\n",
    "ax[1].set_title('Original image''\\nFlux [e-]: %.2E''\\nWvl: %.3fnm'%(np.sum(resize_array(img,128)),wvl))\n",
    "\n",
    "divider = make_axes_locatable(ax[2])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "im2 = ax[2].imshow(resize_array(img-estim,128),cmap = 'gray')\n",
    "fig.colorbar(im2, cax ,ax=ax[2])\n",
    "ax[2].set_title('Difference''\\nFlux Diff (%%): %.2f'%(100*np.sum(resize_array(img-estim,128))/np.sum(resize_array(img,128))), fontsize = 14)\n",
    "\n",
    "\n",
    "\n",
    "print(wvl)\n",
    "\n",
    "fig.savefig('test.pdf')\n",
    "\n",
    "# fig.savefig('/Users/alau/Data/amiral_fits/VESTA/SNR/2021apr06/deconv/VESTA_noise_free_residual.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "rcParams['figure.figsize'] = 3,3\n",
    "fig.tight_layout(pad=1.0, w_pad=1.0, h_pad=5.0)\n",
    "\n",
    "ft_img = np.fft.fft2(img)\n",
    "ax.imshow(np.log10(np.abs(np.fft.fftshift(ft_img))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "rcParams['figure.figsize'] = 9,6\n",
    "\n",
    "fig.tight_layout(pad=1.0, w_pad=1.0, h_pad=5.0)\n",
    "\n",
    "ft_img = np.fft.fft2(img)\n",
    "\n",
    "ax.plot(utils.mean_cir_array(np.abs(np.fft.fftshift(ft_img))))\n",
    "ax.set_title('OTF')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# dec = Deconvbench(obs_image,psf_total,ron = 10)\n",
    "# dec.verbose_modulo = 100 # print every 10 iteration\n",
    "# dec.regularization.scale *= 2. # sharpen details (reduce regularization)\n",
    "# estim_1 = dec.run()\n",
    "\n",
    "# end_time = time.time()\n",
    "# runtime = end_time - start_time\n",
    "\n",
    "# print(\"Run Time (mintues): \",runtime/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perfect_deconv = estim_1\n",
    "\n",
    "# zoom_diff = zoom_array(estim-perfect_deconv, 200)\n",
    "# zoom_deconv = zoom_array(perfect_deconv, 200)\n",
    "\n",
    "# fig, ax = plt.subplots(1,2)\n",
    "\n",
    "# rcParams['figure.figsize'] = 16,19\n",
    "\n",
    "# divider = make_axes_locatable(ax[0])\n",
    "# cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "# im = ax[0].imshow(zoom_deconv)\n",
    "# fig.colorbar(im,cax ,ax=ax[0])\n",
    "# ax[0].set_title('L2-L1 Deconvolved with the exact PSF''\\nFlux [e-]: %.2E' %(np.sum(perfect_deconv)), fontsize = 14)\n",
    "\n",
    "# divider = make_axes_locatable(ax[1])\n",
    "# cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "# im1 = ax[1].imshow(zoom_diff)\n",
    "# fig.colorbar(im1, cax ,ax=ax[1])\n",
    "# ax[1].set_title('Residual (Estimated_PSF - True_PSF)\\nDiff(SR) = %.2f %%\\nFlux Difference: %.2f %%\\nr0 = %.2f cm sig2 = %.2f'\n",
    "#              %(diff_SR,np.sum(obs_image-perfect_deconv)/np.sum(obs_image), 100*psf_param[0], psf_param[2]), fontsize = 14)\n",
    "\n",
    "\n",
    "# print(np.sum(obs_image-perfect_deconv)/np.sum(obs_image))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# rcParams['figure.figsize'] = 33 ,24\n",
    "\n",
    "# im = ax.imshow(np.abs(estim-perfect_deconv))\n",
    "# fig.colorbar(im, ax=ax)\n",
    "# ax.set_title('Exact PSF Residual(Normalised)\\nDiff(SR) = 2.16%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# rcParams['figure.figsize'] = 33 ,24\n",
    "\n",
    "# im = ax.imshow(asteriod_resize)\n",
    "# fig.colorbar(im, ax=ax)\n",
    "# ax.set_title('Object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from deconvbench.stat import DSPFit, Circmoyto2D\n",
    "# from deconvbench import RegulPSD\n",
    "\n",
    "# rho, psd_param, _, psd1d = DSPFit(obs_image)\n",
    "# psd1 = Circmoyto2D(rho,psd1d,obs_image.shape[0])\n",
    "\n",
    "# hyper = est_crtierion[-3:-1]\n",
    "\n",
    "\n",
    "# psd_object = psd_object(hyper)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # plot PSD\n",
    "\n",
    "# rcParams['figure.figsize'] = 13 ,11\n",
    "\n",
    "# ycent = int((psf_total.shape[0]//2))\n",
    "    \n",
    "# fig, ax = plt.subplots()\n",
    "# ax.set_xscale('log')\n",
    "# ax.set_yscale('log')\n",
    "# ax.plot(utils.mean_cir_array(np.real(psd1)), label = \"True\")\n",
    "# ax.plot(utils.mean_cir_array(np.real(est_psf)), label = \"Estimated PSF\")\n",
    "\n",
    "# ax.legend()\n",
    "\n",
    "# print(psd_param)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #%% ITERATIVE DECONVOLUTION\n",
    "# dec_psd1 = Deconvbench(obs_image, est_psf, ron=10, positivity=False, verbose=True)\n",
    "# dec_psd1.verbose_modulo = 50\n",
    "# dec_psd1.regularization = RegulPSD(psd1) # set PSD regularization\n",
    "# estD1 = dec_psd1.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# rcParams['figure.figsize'] = 33 ,24\n",
    "\n",
    "# im = ax.imshow(estD1)\n",
    "# fig.colorbar(im, ax=ax)\n",
    "# ax.set_title('Deconv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from deconvbench.stat import DSPFit, Circmoyto2D\n",
    "# from deconvbench import RegulPSD\n",
    "\n",
    "# rho, psd_param, _, psd1d = DSPFit(obs_image)\n",
    "# psd1 = Circmoyto2D(rho,psd1d,obs_image.shape[0])\n",
    "\n",
    "\n",
    "# #%% ITERATIVE DECONVOLUTION\n",
    "# dec_psd = Deconvbench(obs_image, psf_total, ron=10, positivity=False, verbose=True)\n",
    "# dec_psd.verbose_modulo = 50\n",
    "# dec_psd.regularization = RegulPSD(psd1) # set PSD regularization\n",
    "# estD = dec_psd.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1,3)\n",
    "\n",
    "# rcParams['figure.figsize'] = 33 ,24\n",
    "\n",
    "# divider = make_axes_locatable(ax[0])\n",
    "# cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "# im = ax[0].imshow(estD)\n",
    "# fig.colorbar(im, cax, ax = ax[0])\n",
    "# ax[0].set_title('PSD Regularisation (With exact PSF)',fontsize = '18')\n",
    "\n",
    "# divider = make_axes_locatable(ax[1])\n",
    "# cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "# im1 = ax[1].imshow(estD1)\n",
    "# fig.colorbar(im1, cax, ax = ax[1])\n",
    "# ax[1].set_title('PSD Regularisation (With estimated PSF)',fontsize = '18')\n",
    "\n",
    "\n",
    "# divider = make_axes_locatable(ax[2])\n",
    "# cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "# im2 = ax[2].imshow(obs_image)\n",
    "# fig.colorbar(im2, cax ,ax=ax[2])\n",
    "# ax[2].set_title('Observed Image',fontsize = '18')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import RGB and form a RGB image\n",
    "# data_path = [\"ganymede_6051_02\",  \"ganymede_5051_02\", \"ganymede_4749_77\"]\n",
    "\n",
    "_R_data = fits.open(data_path[0]+\"_test\"+\".fits\")\n",
    "R_data = _R_data[0].data\n",
    "\n",
    "_G_data = fits.open(data_path[1]+\"_test\"+\".fits\")\n",
    "G_data = _G_data[0].data\n",
    "\n",
    "_B_data = fits.open(data_path[2]+\"_test\"+\".fits\")\n",
    "B_data = _B_data[0].data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = make_lupton_rgb(R_data, G_data, B_data)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(R_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(G_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(B_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "dirname = os.path.dirname(wdir+data_cube[1]+\".fits\")\n",
    "print(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
