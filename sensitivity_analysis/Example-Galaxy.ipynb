{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "\n",
    "# Packages required\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from astropy.io import fits\n",
    "import os\n",
    "from amiral import instructment, utils, parameter, gradient, minimisation, array\n",
    "from scipy.optimize import minimize \n",
    "%matplotlib inline\n",
    "from deconvbench import Deconvbench\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting snr\n",
    "def get_snr (array, noise):\n",
    "    \n",
    "    mean = np.mean(array)\n",
    "    sig2 = np.std(noise)\n",
    "    \n",
    "    snr = mean / sig2\n",
    "    \n",
    "    return snr\n",
    "\n",
    "def psd_object (param):\n",
    "    \n",
    "    rho = np.fft.fftshift(utils.dist(512))/param[1]\n",
    "    psd_obj =  param[0]/ (np.power(rho,param[2]) + 1.)\n",
    "    \n",
    "    return psd_obj\n",
    "    \n",
    "def plot_psd_object(psd_obj): \n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ycent = int((256*aosys_cls.samp_factor[0])//2)\n",
    "\n",
    "    ax.plot(np.abs(psd_obj[ycent,...]))\n",
    "    ax.set_title('PSD Object(total)')\n",
    "    ax.axhline(y=1, color = 'r', ls = '--')\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "def forced_zero (array):\n",
    "\n",
    "    \"\"\"\n",
    "    Checking the input image array and make sure there is no zero in the input array \n",
    "    Since the input array is treated as an object, val < 0 / = nan would result in error \n",
    "    while estimating the photon noise of your simulated observations\n",
    "\n",
    "\n",
    "    Args:\n",
    "        array ([type]): [description]\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "    \n",
    "    ind = np.where(array < 0)\n",
    "\n",
    "    if ((len(ind))) != 0: \n",
    "        array[ind] = 0.\n",
    "        return array\n",
    "\n",
    "    else: \n",
    "        return array\n",
    "    \n",
    "    \n",
    "def create_psfao19_otf (otf_tel, guess, aosys_cls): \n",
    "    \n",
    "    # Use PSFAO19 model to create a PSF\n",
    "    psd_ao = aosys_cls.psd_residual_ao (guess = guess)\n",
    "    psd_halo = aosys_cls.psd_residual_halo(r0 = guess[0])\n",
    "    \n",
    "    psd = psd_ao + psd_halo\n",
    "\n",
    "    otf_atmo = aosys_cls.otf_atmo(psd)\n",
    "    otf_total = otf_atmo*otf_tel\n",
    "    \n",
    "    \n",
    "    return otf_atmo,otf_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH\n",
    "\n",
    "# Parameters for the PSF\n",
    "psf_dict = {\n",
    "    \"r0\": 0.15,                  \n",
    "    \"background\": 0.,      \n",
    "    \"amplitude\": 1.5,       \n",
    "    \"ax\": 0.05,                            \n",
    "    \"beta\": 1.5, \n",
    "    \"mu\": 0., \n",
    "    \"rho0\": 0., \n",
    "    \"p\": 0. \n",
    "}\n",
    "\n",
    "# Variable\n",
    "RON = 10. # CCD read-out noise standard-deviation [e-]\n",
    "FLUX = np.linspace(5e6,5e9,10)\n",
    "DIMENSION = int(720*3)\n",
    "\n",
    "flux_snr = FLUX[9]\n",
    "print(flux_snr)\n",
    "\n",
    "# psf_dict[\"r0\"] = 0.1\n",
    "# psf_dict[\"amplitude\"] = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_galaxy = '/Users/alau/Data/mock_sloan_data/Sbc_300_g_0.fits'\n",
    "_gal = fits.open(path_galaxy)\n",
    "gal = _gal[0].data\n",
    "\n",
    "\n",
    "dim = gal.shape[0]\n",
    "\n",
    "print(dim)\n",
    "gal_resize = np.zeros((dim*3,dim*3))\n",
    "\n",
    "\n",
    "cuta = int(dim*3//2-(dim/2))\n",
    "cutb = int(dim*3//2+(dim/2))\n",
    "\n",
    "print(cuta)\n",
    " \n",
    "gal_resize[cuta:cutb,cuta:cutb] = gal\n",
    "\n",
    "# Calibrating the flux\n",
    "gal_resize = forced_zero(gal_resize)\n",
    "gal_resize = gal_resize/np.sum(gal_resize)*flux_snr\n",
    "\n",
    "\n",
    "img = gal_resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 33 ,24\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.tight_layout(pad=0.4, w_pad=0.5, h_pad=2.0)\n",
    "\n",
    "im = ax[0].imshow(np.real(gal))\n",
    "ax[0].set_title('Image')\n",
    "fig.colorbar(im, ax=ax[0])\n",
    "\n",
    "im1 = ax[1].imshow(np.real(img))\n",
    "ax[1].set_title('Estimated Object')\n",
    "fig.colorbar(im1, ax=ax[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a PSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the telescope and produce a PSF\n",
    "amiral_dict = {\n",
    "    \"r0\": 0.20,                  \n",
    "    \"background\": 0.,      \n",
    "    \"amplitude\": 1.5,       \n",
    "    \"ax\": 0.05,                            \n",
    "    \"beta\": 1.5, \n",
    "    \"mu\": 0., \n",
    "    \"rho0\": 0., \n",
    "    \"p\": 0. \n",
    "}\n",
    "\n",
    "aosys_dict = {\n",
    "    'diameter': 8 , \n",
    "    'occ_ratio': 0.14, \n",
    "    'no_acutuator' : 20, \n",
    "    'wavelength': 500, \n",
    "    'dimension': 720,\n",
    "    'resolution_rad' : 2.083e-8\n",
    "}\n",
    "\n",
    "# Passing parametpsd_arrayers from the telesope to the aosystem\n",
    "aosys_cls = instructment.aoSystem( \n",
    "        diameter = aosys_dict['diameter'], occ_ratio = aosys_dict['occ_ratio'], \n",
    "        no_acutuator= aosys_dict['no_acutuator'], wavelength = aosys_dict['wavelength']*1e-9, \n",
    "        resolution_rad = aosys_dict['resolution_rad'], \n",
    "        dimension=aosys_dict['dimension'])  \n",
    "\n",
    "\n",
    "psf_keys, psf_param = utils.dict2array(psf_dict)\n",
    "amiral_keys, psf_guess = utils.dict2array(amiral_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "psd_ao = aosys_cls.psd_residual_ao (psf_param)\n",
    "psd_halo = aosys_cls.psd_residual_halo(psf_dict['r0'])\n",
    "\n",
    "psd = psd_halo + psd_ao \n",
    "\n",
    "pupil = aosys_cls.get_pupil_plane()\n",
    "otf_tel = aosys_cls.pupil_to_otf_tel(pupil)\n",
    "psf_tel = np.fft.ifft2(np.fft.fftshift(otf_tel))\n",
    "\n",
    "integral, SR = aosys_cls.psd_integral(psd_ao, psf_dict['r0'])\n",
    "\n",
    "otf_atmo = aosys_cls.otf_atmo(psd)\n",
    "\n",
    "otf_total = np.fft.ifftshift(otf_atmo * otf_tel)\n",
    "\n",
    "psf_total = aosys_cls.psfao(otf_total)\n",
    "print(np.shape(psf_total))\n",
    "\n",
    "plt.imshow(np.log10(np.real(psf_tel)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise \n",
    "gauss_noise = np.random.randn(np.shape(gal_resize)[0],np.shape(gal_resize)[0])*RON\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "photon_noise = rng.poisson(gal_resize)\n",
    "\n",
    "noise = gauss_noise + photon_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_obj = np.fft.fft2(np.fft.ifftshift(gal_resize))\n",
    "\n",
    "ft_image = ft_obj*otf_total\n",
    "\n",
    "_obj = np.real(np.fft.ifft2(ft_image))\n",
    "\n",
    "_obj = forced_zero(_obj)\n",
    "\n",
    "\n",
    "noise = photon_noise + gauss_noise\n",
    "\n",
    "empty_arr = np.zeros((DIMENSION,DIMENSION))+1.\n",
    "\n",
    "psd_noise = np.average(ft_image)*empty_arr\n",
    "psd_asteroid = np.abs(ft_image)**2\n",
    "\n",
    "snr = psd_asteroid/psd_noise\n",
    "\n",
    "est_obj = tools.wiener_filter(ft_image,otf_total,snr)\n",
    "\n",
    "# obs_image = noise + _obj\n",
    "obs_image = _obj\n",
    "\n",
    "img = obs_image\n",
    "\n",
    "plt.imshow(np.real(np.log10(otf_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snr_scalar = get_snr(ft_img_noise**2, tools.fft2D(noise)**2)\n",
    "# print(snr_scalar)\n",
    "\n",
    "# observed_noisy_image = tools.ifft2D(ft_img_noise, norm = True)\n",
    "\n",
    "# plt.imshow(np.real(observed_noisy_image))\n",
    "print(\"Sum: \", np.sum(gal_resize))\n",
    "print(\"Sum: \", np.sum(obs_image))\n",
    "print(\"Noise of the object: \", np.sum(noise))\n",
    "print(\"Retrieved Flux: \",np.sum(obs_image) - np.sum(noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty_arr = np.zeros((DIMENSION,DIMENSION))+1.\n",
    "\n",
    "# psd_noise = np.average(observed_noisy_image)*empty_arr\n",
    "# psd_asteroid = np.abs(ft_img_noise)**2\n",
    "\n",
    "# snr = psd_asteroid/psd_noise\n",
    "\n",
    "\n",
    "# est_obj = tools.wiener_filter(ft_img_noise,otf_total,snr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1,2)\n",
    "\n",
    "# rcParams['figure.figsize'] = 33 ,24\n",
    "\n",
    "# im = ax[0].imshow(np.real(est_obj))\n",
    "# fig.colorbar(im, ax=ax[0])\n",
    "# ax[0].set_title('Estimated Object')\n",
    "\n",
    "# im1 = ax[1].imshow(np.real(observed_noisy_image))\n",
    "# fig.colorbar(im1, ax=ax[1])\n",
    "# ax[1].set_title('Observed Image')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nFlux of the object: \", np.sum(asteriod_resize))\n",
    "# print(\"\\nNoise ofthe object: \", np.sum(np.abs(noise)))\n",
    "# print(\"\\nSNR: \", np.sum(asteriod_resize)/np.sum(np.abs(noise)))\n",
    "\n",
    "# print(snr_scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Sum: \", np.sum(est_obj))\n",
    "# print(\"Noise of the object: \", np.sum(noise))\n",
    "# print(\"Retrieved Flux: \",np.sum(est_obj) - np.sum(noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = np.real(np.fft.fftshift(observed_noisy_image))\n",
    "\n",
    "# _img = fits.open(\"/Users/alau/Data/amiral_fits/VESTA/SNR/case_0/VESTA_84.fits\")\n",
    "# img = _img[0].data\n",
    "\n",
    "amiralparam = parameter.amiralParam(img ,guess = psf_guess, aosys = aosys_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What variables to be minimised\n",
    "param_mask = np.asarray([1,1,0,0,0])\n",
    "hyper_param_mask = np.asarray([1,1,1])\n",
    "\n",
    "mask = np.concatenate((param_mask,hyper_param_mask))\n",
    "\n",
    "hyper_guess = amiralparam.hyperparam_initial(psf_guess, debug = True)\n",
    "hyper_min, hyper_max = amiralparam.hyperparam_bound(psf_guess, p_upperbound = 100., debug = True)\n",
    "\n",
    "psf_guess[-3] = hyper_guess[0] \n",
    "psf_guess[-2] = hyper_guess[1] \n",
    "psf_guess[-1] = hyper_guess[2] \n",
    "\n",
    "param_min = np.asarray([0.05,0,0,1e-8,1.01])\n",
    "param_max =  np.asarray([1.,1e8,1e8,1e3,10])\n",
    "\n",
    "upperbound = np.concatenate((param_max, hyper_max))\n",
    "lowerbound = np.concatenate((param_min, hyper_min))\n",
    "\n",
    "param_numerical_condition = np.array([1., 1e-4, 1., 1., 1.])\n",
    "hyperparam_numerical_condition = np.array([hyper_guess[0], hyper_guess[1], 1.])\n",
    "\n",
    "numerical_condition = np.concatenate((param_numerical_condition, hyperparam_numerical_condition))\n",
    "\n",
    "amiral_cls = parameter.amiral(img=img, guess=psf_guess, aosys = aosys_cls, upperbound = upperbound, lowerbound= lowerbound, numerical_condition = numerical_condition, fourier_variable = amiralparam.fourier_variable, mask = mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "est_criterion, value_criterion, value_grad = amiral_cls.minimisation(psf_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(est_criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_otf_atmo, est_otf = create_psfao19_otf(otf_tel, est_criterion[0:5], aosys_cls)\n",
    "est_psf = np.fft.ifft2(np.fft.ifftshift(est_otf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_SR = np.max(np.real(est_psf)) / np.max(np.real(psf_tel))\n",
    "SR = np.max(psf_total) / np.max(psf_tel)\n",
    "\n",
    "# Plot the PSF slice\n",
    "rcParams['figure.figsize'] = 13 ,11\n",
    "\n",
    "ycent = int((psf_total.shape[0]//2))\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_title(r\"PSF Estimation (without noise)$\\mathrm{ \\{r_0, sig^2, mu, \\rho_0 \\}}$\",fontsize = 14)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel(r'$\\mathrm{Mean Intensity [e^-]}$', fontsize = 14)\n",
    "ax.set_xlabel(r'$\\mathrm{Position [pixel]}$', fontsize = 14)\n",
    "ax.plot(utils.mean_cir_array(np.real(psf_total)), label = \"True\")\n",
    "ax.plot(utils.mean_cir_array(np.real(est_psf)), label = \"Estimated PSF\")\n",
    "ax.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.real(est_SR-SR)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dec = Deconvbench(img,est_psf,ron = 10)\n",
    "# dec.verbose_modulo = 10 # print every 10 iteration\n",
    "# dec.regularization.scale *= 4. # sharpen details (reduce regularization)\n",
    "# estim = dec.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estim_norm = estim/gal_resize.max()\n",
    "# gal_resize_norm = gal_resize/gal_resize.max()\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(1,2)\n",
    "\n",
    "# rcParams['figure.figsize'] = 33 ,24\n",
    "\n",
    "# im = ax[0].imshow(np.abs(estim_norm-gal_resize_norm))\n",
    "# fig.colorbar(im, ax=ax[0])\n",
    "# ax[0].set_title('Residual (Normalised)\\nDiff(SR) = 2.16%')\n",
    "\n",
    "# im1 = ax[1].imshow(np.abs(gal_resize-estim))\n",
    "# fig.colorbar(im1, ax=ax[1])\n",
    "# ax[1].set_title('Residual\\nDiff(SR) = 2.16%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dec = Deconvbench(img,psf_total,ron = 10)\n",
    "# dec.verbose_modulo = 10 # print every 10 iteration\n",
    "# dec.regularization.scale *= 4. # sharpen details (reduce regularization)\n",
    "# estim_1 = dec.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
